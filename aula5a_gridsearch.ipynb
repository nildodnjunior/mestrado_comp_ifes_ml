{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nildodnjunior/mestrado_comp_ifes_ml/blob/master/aula5a_gridsearch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dataset com pessoas que possuem ou não problemas de fígado. Classificação binária\n",
        "\n",
        "Obtido em https://openml.org/search?type=data&status=active&id=1480"
      ],
      "metadata": {
        "id": "sw_Mf-UeAo9A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import fetch_openml\n",
        "ilpd = fetch_openml(name='ilpd', version=1, parser='auto')\n",
        "X, y = ilpd.data.to_numpy(), ilpd.target.to_numpy()"
      ],
      "metadata": {
        "id": "JYrK_hJaSBHO"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X[:,1] = (X[:,1] == 'Male').astype(int) #Convertendo Male = 1, Female = 0\n",
        "y = y.astype(int)-1 #Convertendo valores de texto no original para 0 e 1 (0 = não tem problema, 1 = tem problema)"
      ],
      "metadata": {
        "id": "nXfIJ_joSFjp"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Separação das bases de treino e teste\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "Xtr, Xte, ytr, yte = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "Xtr.shape, ytr.shape, Xte.shape, yte.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2n8w4APXwKhW",
        "outputId": "4f099013-9b45-4309-d9ef-b914a383765b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((466, 10), (466,), (117, 10), (117,))"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Usando SMOTE para rebalancear a base de treino, pois há uma proporção de aproximadamente 28/72% entre as classes positivas e negativas para essa base\n",
        "#Após o balanceamento fica em 50%\n",
        "from imblearn.over_sampling import SMOTE\n",
        "sm = SMOTE(random_state = 42)\n",
        "print(f\"Balanceamento original: {sum(ytr)/len(ytr)}\")\n",
        "Xtr, ytr = sm.fit_resample(Xtr, ytr.ravel())\n",
        "print(f\"Balanceamento após SMOTE: {sum(ytr)/len(ytr)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cpqZ5aboDU1J",
        "outputId": "618aaf90-24fa-4d22-f481-eda615d7575f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Balanceamento original: 0.2939914163090129\n",
            "Balanceamento após SMOTE: 0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, RepeatedStratifiedKFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import mean_squared_error, make_scorer, accuracy_score, roc_auc_score, recall_score\n",
        "import numpy as np\n",
        "from sklearn.model_selection import cross_validate\n",
        "from scipy.stats import randint\n",
        "\n",
        "pipe = Pipeline([\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('clf', LogisticRegression())\n",
        "])\n",
        "params_LR = {\n",
        "    'scaler__with_mean': [True, False],\n",
        "    'clf__solver': ['liblinear', 'newton-cg', 'lbfgs'],\n",
        "    'clf__C': [0.1, 0.5, 0.8, 1.0],\n",
        "    'clf__tol': [1e-5, 1e-4, 1e-3, 1e-2],\n",
        "    'clf__max_iter': [300, 600, 1000]\n",
        "}\n",
        "\n",
        "#Usando recall pois é mais importante detectar se a pessoa tem problema do que não\n",
        "modelo_aninhado_LR = GridSearchCV(pipe, params_LR, verbose=1, scoring=make_scorer(recall_score))\n",
        "\n",
        "scores_LR = cross_validate(modelo_aninhado_LR, Xtr, ytr, return_estimator=True,\n",
        "                        scoring=make_scorer(recall_score))\n",
        "print(f\"Média dos scores: {np.mean(scores_LR['test_score'])}\")\n",
        "print(\"Melhores modelos:\")\n",
        "for modelo_LR, score in zip(scores_LR['estimator'], scores_LR['test_score']):\n",
        "    print(modelo_LR.best_params_, score)\n",
        "    print(f\"Métrica na base de teste: {recall_score(yte, modelo_LR.predict(Xte))}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8R7nZYCyISQu",
        "outputId": "b04801f7-e005-46bd-d3c2-d10c994218b9"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 288 candidates, totalling 1440 fits\n",
            "Fitting 5 folds for each of 288 candidates, totalling 1440 fits\n",
            "Fitting 5 folds for each of 288 candidates, totalling 1440 fits\n",
            "Fitting 5 folds for each of 288 candidates, totalling 1440 fits\n",
            "Fitting 5 folds for each of 288 candidates, totalling 1440 fits\n",
            "Média dos scores: 0.8662937062937063\n",
            "Melhores modelos:\n",
            "{'clf__C': 0.1, 'clf__max_iter': 300, 'clf__solver': 'liblinear', 'clf__tol': 1e-05, 'scaler__with_mean': True} 0.8636363636363636\n",
            "Métrica na base de teste: 0.9\n",
            "{'clf__C': 0.1, 'clf__max_iter': 300, 'clf__solver': 'liblinear', 'clf__tol': 0.01, 'scaler__with_mean': True} 0.8636363636363636\n",
            "Métrica na base de teste: 0.9\n",
            "{'clf__C': 0.1, 'clf__max_iter': 300, 'clf__solver': 'liblinear', 'clf__tol': 1e-05, 'scaler__with_mean': True} 0.8939393939393939\n",
            "Métrica na base de teste: 0.9333333333333333\n",
            "{'clf__C': 0.1, 'clf__max_iter': 300, 'clf__solver': 'liblinear', 'clf__tol': 1e-05, 'scaler__with_mean': True} 0.8769230769230769\n",
            "Métrica na base de teste: 0.9333333333333333\n",
            "{'clf__C': 0.1, 'clf__max_iter': 300, 'clf__solver': 'liblinear', 'clf__tol': 1e-05, 'scaler__with_mean': True} 0.8333333333333334\n",
            "Métrica na base de teste: 0.9333333333333333\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import mean_squared_error, make_scorer, accuracy_score, roc_auc_score, recall_score\n",
        "import numpy as np\n",
        "from sklearn.model_selection import cross_validate\n",
        "from scipy.stats import randint\n",
        "\n",
        "pipe = Pipeline([\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('clf', RandomForestClassifier())\n",
        "])\n",
        "params_RF = {\n",
        "    'scaler__with_mean': [True, False],\n",
        "    'clf__criterion': ['gini', 'entropy', 'log_loss'],\n",
        "    'clf__max_depth': [1, 5, 10, 15, 20],\n",
        "    'clf__n_estimators': [50, 100, 200, 400]\n",
        "}\n",
        "\n",
        "modelo_aninhado_RF = GridSearchCV(pipe, params_RF, verbose=1, scoring=make_scorer(recall_score))\n",
        "\n",
        "scores_RF = cross_validate(modelo_aninhado_RF, Xtr, ytr, return_estimator=True,\n",
        "                        scoring=make_scorer(recall_score))\n",
        "print(f\"Média dos scores: {np.mean(scores_RF['test_score'])}\")\n",
        "print(\"Melhores modelos:\")\n",
        "for modelo_RF, score in zip(scores_RF['estimator'], scores_RF['test_score']):\n",
        "    print(modelo_RF.best_params_, score)\n",
        "    print(f\"Métrica na base de teste: {recall_score(yte, modelo_RF.predict(Xte))}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "byKo7lOp_HgM",
        "outputId": "61f983e1-3398-44a2-9ca7-8c12782059b7"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 120 candidates, totalling 600 fits\n",
            "Fitting 5 folds for each of 120 candidates, totalling 600 fits\n",
            "Fitting 5 folds for each of 120 candidates, totalling 600 fits\n",
            "Fitting 5 folds for each of 120 candidates, totalling 600 fits\n",
            "Fitting 5 folds for each of 120 candidates, totalling 600 fits\n",
            "Média dos scores: 0.8633566433566433\n",
            "Melhores modelos:\n",
            "{'clf__criterion': 'log_loss', 'clf__max_depth': 1, 'clf__n_estimators': 50, 'scaler__with_mean': False} 0.8333333333333334\n",
            "Métrica na base de teste: 0.9333333333333333\n",
            "{'clf__criterion': 'entropy', 'clf__max_depth': 1, 'clf__n_estimators': 50, 'scaler__with_mean': False} 0.803030303030303\n",
            "Métrica na base de teste: 0.9333333333333333\n",
            "{'clf__criterion': 'entropy', 'clf__max_depth': 1, 'clf__n_estimators': 50, 'scaler__with_mean': False} 0.8787878787878788\n",
            "Métrica na base de teste: 0.9666666666666667\n",
            "{'clf__criterion': 'log_loss', 'clf__max_depth': 1, 'clf__n_estimators': 50, 'scaler__with_mean': True} 0.9076923076923077\n",
            "Métrica na base de teste: 0.9666666666666667\n",
            "{'clf__criterion': 'log_loss', 'clf__max_depth': 5, 'clf__n_estimators': 50, 'scaler__with_mean': False} 0.8939393939393939\n",
            "Métrica na base de teste: 0.9\n"
          ]
        }
      ]
    }
  ]
}